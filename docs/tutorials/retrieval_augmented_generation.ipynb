{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f333a0-7450-4136-b8cc-416e07426279",
   "metadata": {
    "id": "f6f333a0-7450-4136-b8cc-416e07426279"
   },
   "source": [
    "# Interroger des documents (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ca9bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f9ca9bf",
    "outputId": "4112b46b-4271-4696-cf31-393e9e7ff8b3"
   },
   "outputs": [],
   "source": [
    "%pip install -qU wget openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a5a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client configuration\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "base_url = \"https://albert.api.etalab.gouv.fr/v1\"\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "\n",
    "session = requests.session()\n",
    "session.headers = {\"Authorization\": f\"Bearer {api_key}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadba81-54dd-48ba-b6f0-fc8307e822c3",
   "metadata": {
    "id": "daadba81-54dd-48ba-b6f0-fc8307e822c3"
   },
   "source": [
    "Commençons par télécharger le document que nous souhaitons interroger. Ce document peut être un pdf, un fichier html ou un fichier json.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80daa99-3416-4b81-a8aa-4fb7427bbe6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "e80daa99-3416-4b81-a8aa-4fb7427bbe6c",
    "outputId": "abf16516-2ef9-40c3-dcad-74b6f9aa42e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_document.pdf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download a file\n",
    "import wget\n",
    "import os\n",
    "\n",
    "file_path = \"my_document.pdf\"\n",
    "if not os.path.exists(file_path):\n",
    "    doc_url = \"https://www.legifrance.gouv.fr/download/file/rxcTl0H4YnnzLkMLiP4x15qORfLSKk_h8QsSb2xnJ8Y=/JOE_TEXTE\"\n",
    "\n",
    "wget.download(doc_url, out=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RkAjTc20Agr9",
   "metadata": {
    "id": "RkAjTc20Agr9"
   },
   "source": [
    "Pour commencer, nous créons une collection nommée `tutorial`. Pour cela nous effectuons une requête GET sur l'endpoint `/v1/models` afin d'obtenir la liste des modèles disponibles et définissons le modèle d'embeddings à utiliser.\n",
    "\n",
    "Nous allons avoir besoin également d'un modèle de langage. Nous appelons le endpoint `/v1/models` pour obtenir la liste des modèles. Les modèles de langage ont le type *text-generation* et les modèles d'embeddings le type *text-embeddings-inference*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Q_5YNzmR_JcK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_5YNzmR_JcK",
    "outputId": "01554f0f-3d01-4946-993f-56e657904898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language model: AgentPublic/llama3-instruct-8b\n",
      "embeddings model: BAAI/bge-m3\n"
     ]
    }
   ],
   "source": [
    "language_model, embeddings_model = None, None\n",
    "\n",
    "for model in client.models.list().data:\n",
    "    if model.type == \"text-generation\" and language_model is None:\n",
    "        language_model = model.id\n",
    "    if model.type == \"text-embeddings-inference\" and embeddings_model is None:\n",
    "        embeddings_model = model.id\n",
    "\n",
    "print(f\"language model: {language_model}\\nembeddings model: {embeddings_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f0adf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection ID: 646672ab-b65f-4091-9054-986f732faec8\n"
     ]
    }
   ],
   "source": [
    "collection = \"tutorial\"\n",
    "\n",
    "response = session.post(f\"{base_url}/collections\", json={\"name\": collection, \"model\": embeddings_model})\n",
    "response = response.json()\n",
    "collection_id = response[\"id\"]\n",
    "print(f\"Collection ID: {collection_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9615d41-5ce2-471b-bd6c-90cfb2b78d21",
   "metadata": {
    "id": "a9615d41-5ce2-471b-bd6c-90cfb2b78d21"
   },
   "source": [
    "Enfin pour nous importons le document dans la collection de notre base vectorielle à l'aide du endpoint POST `/v1/files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6852fc7a-0b09-451b-bbc2-939fa96a4d28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6852fc7a-0b09-451b-bbc2-939fa96a4d28",
    "outputId": "8555033d-d20f-4b0b-8bfa-7fa5c83a299b"
   },
   "outputs": [],
   "source": [
    "files = {\"file\": (os.path.basename(file_path), open(file_path, \"rb\"), \"application/pdf\")}\n",
    "data = {\"request\": '{\"collection\": \"%s\"}' % collection_id}\n",
    "response = session.post(f\"{base_url}/files\", data=data, files=files)\n",
    "assert response.status_code == 201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ec73c-3e83-4266-a8de-c6a198f317b4",
   "metadata": {
    "id": "f78ec73c-3e83-4266-a8de-c6a198f317b4"
   },
   "source": [
    "Nous pouvons observer que le fichier que nous avons importé est bien dans la collection à l'aide du endpoint GET `/v1/documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6d6140-5c91-4c3e-9350-b6c8550ab145",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd6d6140-5c91-4c3e-9350-b6c8550ab145",
    "outputId": "0ddea4bb-889e-4ebc-a912-7a2e461ea987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in collection: 2\n"
     ]
    }
   ],
   "source": [
    "response = session.get(f\"{base_url}/documents/{collection_id}\")\n",
    "assert response.status_code == 200\n",
    "files = response.json()[\"data\"]\n",
    "print(f\"Number of files in collection: {len(files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd3aed3",
   "metadata": {},
   "source": [
    "Maintenant que nous avons notre collection et notre fichier, nous pouvons faire une recherche vectorielle à l'aide du endpoint POST `/v1/search`. Ces résutats de recherche vectorielle seront utilisés pour générer une réponse à l'aide du modèle de langage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67a01e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Qui est Ulrich Tan ?\"\n",
    "prompt_template = \"Réponds à la question suivante en te basant sur les documents ci-dessous : {prompt}\\n\\nDocuments :\\n\\n{chunks}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ce73cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selon les documents, Ulrich Tan est le chef du pôle Datamin du département \"Etalab\".\n"
     ]
    }
   ],
   "source": [
    "data = {\"collections\": [collection_id], \"k\": 6, \"prompt\": prompt}\n",
    "response = session.post(url=f\"{base_url}/search\", json=data, headers={\"Authorization\": f\"Bearer {api_key}\"})\n",
    "\n",
    "chunks = \"\\n\\n\\n\".join([result[\"chunk\"][\"content\"] for result in response.json()[\"data\"]])\n",
    "sources = set([result[\"chunk\"][\"metadata\"][\"document_name\"] for result in response.json()[\"data\"]])\n",
    "rag_prompt = prompt_template.format(prompt=prompt, chunks=chunks)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=language_model,\n",
    "    stream=False,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11557a2",
   "metadata": {},
   "source": [
    "Nous avons récupéré les sources depuis les metadata de chaque chunk. Nous pouvons constater que les chunks proviennent bien du document que nous avons importé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35eda4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my_document.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a122cb8",
   "metadata": {},
   "source": [
    "Vous pouvez également faire ajouter une recherche sur internet en spécifiant \"internet\" dans la liste des collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f374c1ad-b5ec-4870-a11a-953c7d219f94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f374c1ad-b5ec-4870-a11a-953c7d219f94",
    "outputId": "64279978-1ae5-4bac-f028-bb0899d83d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je suis prêt ! Pourriez-vous me donner les documents qui me permettront de répondre à cette question ?\n"
     ]
    }
   ],
   "source": [
    "data = {\"collections\": [\"internet\"], \"k\": 6, \"prompt\": prompt}\n",
    "response = session.post(url=f\"{base_url}/search\", json=data, headers={\"Authorization\": f\"Bearer {api_key}\"})\n",
    "\n",
    "chunks = \"\\n\\n\\n\".join([result[\"chunk\"][\"content\"] for result in response.json()[\"data\"]])\n",
    "sources = set([result[\"chunk\"][\"metadata\"][\"document_name\"] for result in response.json()[\"data\"]])\n",
    "rag_prompt = prompt_template.format(prompt=prompt, chunks=chunks)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": rag_prompt}],\n",
    "    model=language_model,\n",
    "    stream=False,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f984e",
   "metadata": {},
   "source": [
    "Nous pouvons de la même manière récupérer les sources depuis les metadata de chaque chunk et les afficher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f982989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://www.etalab.gouv.fr/datalab/equipe/'}\n"
     ]
    }
   ],
   "source": [
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad96d70",
   "metadata": {},
   "source": [
    "Enfin il est possible de combiner une recherche dans les fichiers et une recherche sur internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07f6610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D'après les documents, il n'est pas mentionné que Ulrich Tan est quelqu'un. Les documents traitent de sujets tels que l'intelligence artificielle, la technologie, les finances publiques, les géants de la tech, etc., mais il n'y a pas de mention d'une personne nommée Ulrich Tan.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.post(\n",
    "    url=f\"{base_url}/chat/completions\",\n",
    "    json={\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"model\": language_model,\n",
    "        \"stream\": False,\n",
    "        \"n\": 1,\n",
    "        \"rag\": True\n",
    "    },\n",
    "    headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    ")\n",
    "response = response.json()\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3233dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detail': [{'type': 'missing', 'loc': ['body', 'rag_parameters'], 'msg': 'Field required', 'input': {'messages': [{'role': 'user', 'content': 'Qui est Ulrich Tan ?'}], 'model': 'AgentPublic/llama3-instruct-8b', 'stream': False, 'n': 1, 'rag': True}}]}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b641348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
